from os.path import abspath, dirname, join, isfile, normpath, relpath
from mhkit.utils import unorm
from math import isclose
import scipy.interpolate as interp
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import netCDF4
import warnings


def get_all_time (data):
    '''
    retunes all of the time stamps and their associated time index
    Parameters
    ----------
    data: netcdf4 object 
       A netCDF object that contains spatial data, e.g. velocity or shear stress.
       These can be generated by running a Delft3D model.  

    Returns
    -------
      seconds_run: array
        An array of positive integer or float the represents the amount of time
        in seconds that simulation has been running
    '''
    
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be netCDF4 object'
        

    seconds_run = np.ma.getdata(data.variables['time'][:], False)

    return seconds_run

def convert_time (data, time_index=None, seconds_run=None):
    '''
    Output the seconds_run for a time_index and vice versa. The output captains 
    both the time_index and seconds_run. 

    Parameters
    ----------
    data: netcdf4 object 
       A netCDF object that contains spatial data, e.g. velocity or shear stress.
       These can be generated by running a Delft3D model.  
    time_index: int 
        A positive integer to pull the time step from the dataset. 0 being closest
        to time 0. Default is last time step -1.
    seconds_run: int, float
        a positive integer or float the represents the amount of time in seconds 
        that simulation has been running

    Returns
    -------
    QoI: int, float
        The quantity of interest is the unknown value either the time_index or
        the seconds_run. The time_index is a positive integer starting form 0 
        and incrementing until in simulation is complete. The seconds_run is the 
        seconds corresponding to those increments
    '''
    
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be netCDF4 object'
    assert time_index or seconds_run, 'input of time_index or seconds_run needed'
    assert not(time_index and seconds_run), (f'only one time_index or seconds_run'
                                            +' can be input')
    assert isinstance(time_index, (int, float)) or isinstance(seconds_run 
                        (int, float)), 'time input must be a int or float'
   
    
    times = get_all_time(data)
    
    if time_index:
        QoI= times[time_index]
    if seconds_run:
        try: 
            idx=np.where(times == seconds_run)
            QoI=idx[0][0]
        except: 
            idx = (np.abs(times - seconds_run)).argmin()
            QoI= idx
            warnings.warn( f'ERROR: invalid seconds_run. Closest time stamp' 
                          +'found {times[idx]}', stacklevel= 2)

    return QoI


def get_layer_data(data, variable, layer_index= -1 , time_index=-1):
    '''
    Get variable data from netcdf4 object at specified layer and timestep. 

    Parameters
    ----------
    data: netcdf4 object 
       A netCDF object that contains spatial data, e.g. velocity or shear stess.
       These can be generated by running a Delft3D model.  
    variable: string
        Delft3D outputs many vairables that can be called. The full list can be
        found using "data.variables.keys()" in the consol. 
    layer_index: int
         A positve interger to pull out a layer from the dataset. 0 being closest 
         to the surface. Defalt is the bottom layer -1.
    time_index: int 
        A positive interger to pull the time step from the dataset. 0 being closest
        to time 0. Defalt is last time step -1.  

    Returns
    -------
    layer_data: DataFrame
        DataFrame with columns of "x", "y", and "z" location on specified layer, 
        the variable values "v", the "time" the simulation has run.
    '''
    
    assert isinstance(time_index, int), 'time_index  must be a int'
    assert isinstance(layer_index, int), 'layer_index  must be a int'
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be netCDF4 object'
    assert variable in data.variables.keys(), 'variable not recognized'
    coords = str(data.variables[variable].coordinates).split()
    var=data.variables[variable][:]
    max_time_index= data['time'].shape[0]-1 # to account for zero index
    assert time_index <= max_time_index, (f'time_index must be less than the max'
                                         +'time index {max_time_index}')
    assert time_index >= -1, 'time_index must be greater than or equal to -1'
    
    x=np.ma.getdata(data.variables[coords[0]][:], False) 
    y=np.ma.getdata(data.variables[coords[1]][:], False)
    
    if type(var[0][0])== np.ma.core.MaskedArray: 
        max_layer= len(var[0][0])
        
        assert layer_index <= max_layer,( f'layer_index must be less than the max'
                                     + 'layer {max_layer}')
        assert layer_index >= -1, 'layer_index must be greater than or equal to -1'
        v= np.ma.getdata(var[time_index,:,layer_index], False)
        dimensions= 3
    
    else: 
        assert type(var[0][0])== np.float64, 'data not  recognized'
        dimensions= 2
        v= np.ma.getdata(var[time_index,:], False)
        
    #depth 
    cords_to_layers= {'FlowElem_xcc FlowElem_ycc':{'name':'laydim', 
                                    'coords':data.variables['LayCoord_cc'][:]},
                       'FlowLink_xu FlowLink_yu': {'name':'wdim', 
                                'coords':data.variables['LayCoord_w'][:]}}
    layer_dim =  str(data.variables[variable].coordinates)
    
    
    cord_sys= cords_to_layers[layer_dim]['coords']
    layer_percentages= np.ma.getdata(cord_sys, False) #accumulative
    bottom_depth=np.ma.getdata(data.variables['waterdepth'][time_index, :], False)
    water_level= np.ma.getdata(data.variables['s1'][time_index, :], False)
    if layer_dim == 'FlowLink_xu FlowLink_yu':
        #interpolate 
        coords = str(data.variables['waterdepth'].coordinates).split()
        x_laydim=np.ma.getdata(data.variables[coords[0]][:], False) 
        y_laydim=np.ma.getdata(data.variables[coords[1]][:], False)
        points_laydim = np.array([ [x, y] for x, y in zip(x_laydim, y_laydim)])
        
        coords_request = str(data.variables[variable].coordinates).split()
        x_wdim=np.ma.getdata(data.variables[coords_request[0]][:], False) 
        y_wdim=np.ma.getdata(data.variables[coords_request[1]][:], False)
        points_wdim=np.array([ [x, y] for x, y in zip(x_wdim, y_wdim)])
        
        bottom_depth_wdim = interp.griddata(points_laydim, bottom_depth,
                                            points_wdim)
        water_level_wdim = interp.griddata(points_laydim, water_level,
                                            points_wdim)
        
        idx_bd= np.where(np.isnan(bottom_depth_wdim))
        
        for i in idx_bd: 
            bottom_depth_wdim[i]= interp.griddata(points_laydim, bottom_depth,
                                              points_wdim[i], method='nearest')
            water_level_wdim[i]= interp.griddata(points_laydim, water_level,
                                              points_wdim[i], method='nearest')
 
    depth=[]
    
    if dimensions== 2:
        if layer_dim == 'FlowLink_xu FlowLink_yu': 
            z = [bottom_depth_wdim]-water_level_wdim
        else:
            z = [bottom_depth]-water_level
    else:
        if layer_dim == 'FlowLink_xu FlowLink_yu': 
            z = [bottom_depth_wdim*layer_percentages[layer_index]]-water_level_wdim 
        else:
            z = [bottom_depth*layer_percentages[layer_index]]-water_level
    depth=np.append(depth, z)

    time= np.ma.getdata(data.variables['time'][time_index], False)*np.ones(len(x))

    layer= np.array([ [x_i, y_i, z_i, v_i, t_i] for x_i, y_i, z_i, v_i, t_i in
                     zip(x, y, depth, v, time)]) 
    layer_data = pd.DataFrame(layer, columns=['x', 'y', 'z','v', 'time'])


    return layer_data


def create_points(x, y, z):
    '''
    Turns three coordinate inputs into a single output DataFrame of points. 
    The 3 inputs can consist of 3 points, 2 points and 1 array, or 1 point 
    and 2 arrays. The final output DataFrame will consist of a DataFrame with
    every combination of the 3 inputs. 
    
    Parameters
    ----------
    x: float, array or int 
        x values to create points.
    y: float, array or int
        y values to create points.
    z: float, array or int
        z values to create points.

    Returns
    -------
    points: DateFrame 
        DataFrame with columns x, y and z points. 
        
    Example 
    -------
    If the inputs are 2 arrays: [1,2] and [3,4,5] and 1 point [6], the output 
    will contain 6 array combinations of the 3 inputs as shown.
        x   y    z
   0  1.0  3.0  6.0
   1  2.0  3.0  6.0
   2  1.0  4.0  6.0
   3  2.0  4.0  6.0
   4  1.0  5.0  6.0
   5  2.0  5.0  6.0
        
    '''
    
    assert isinstance(x, (int, float, np.ndarray)), ('x must be a int, float'
                                                     +' or array')
    assert isinstance(y, (int, float, np.ndarray)), ('y must be a int, float'
                                                     +' or array')
    assert isinstance(z, (int, float, np.ndarray)), ('z must be a int, float'
                                                     +' or array')
    
    directions = {0:{'name':  'x',
                     'values': x},
                  1:{'name':  'y',
                     'values': y},
                  2:{'name':  'z',
                     'values': z}}

    for i in directions:
        try:
            len(directions[i]['values'])
        except:
            directions[i]['values'] = np.array([directions[i]['values']])  
            
        N= len(directions[i]['values'])
        if N == 1 :
            directions[i]['type']= 'point'
            
        elif N > 1 :
            directions[i]['type']= 'array'
            
        else:
            raise Exception(f'length of direction {directions[i]["name"]} was'
                            +'neagative or zero')
    
    # Check how many times point is in "types" 
    types= [directions[i]['type'] for i in directions]
    N_points = types.count('point')

    if N_points >= 2:
        lens = np.array([len(directions[d]['values'])  for d in directions])
        max_len_idx = lens.argmax()
        not_max_idxs= [i for i in directions.keys()]
        
        del not_max_idxs[max_len_idx]
        print(max_len_idx)
        for not_max in not_max_idxs:     
            N= len(directions[max_len_idx]['values'])
            vals =np.ones(N)*directions[not_max]['values']
            directions[not_max]['values'] = np.array(vals)
                    
        x_new = directions[0]['values']
        y_new = directions[1]['values']
        z_new = directions[2]['values']
            
        request= np.array([ [x_i, y_i, z_i] for x_i, y_i, z_i in zip(x_new, 
                                                             y_new, z_new)]) 
        points= pd.DataFrame(request, columns=[ 'x', 'y', 'z'])
        
    elif N_points == 1: 
        # treat as plane
        #find index of point 
        idx_point = types.index('point')
        max_idxs= [i for i in directions.keys()]
        print(max_idxs)
        del max_idxs[idx_point]
        #find vectors 
        XX, YY = np.meshgrid(directions[max_idxs[0]]['values'],
                             directions[max_idxs[1]]['values'] )
        N_X=np.shape(XX)[1]
        N_Y=np.shape(YY)[0]
        ZZ= np.ones((N_Y,N_X))*directions[idx_point]['values'] 
     
        request= np.array([ [x_i, y_i, z_i] for x_i, y_i, z_i in zip(XX.ravel(),
                            YY.ravel() , ZZ.ravel())]) 
        columns=[ directions[max_idxs[0]]['name'],  
                 directions[max_idxs[1]]['name'],  directions[idx_point]['name']]
        
        points= pd.DataFrame(request, columns=columns)
    else: 
        raise Exception('Can provide at most two arrays')

    return points 


def variable_interpolation(data, variables, points='cells'):
    '''
    Interpolate multiple variables from the Delft3D onto the same points. 

    Parameters
    ----------
    data: netcdf4 object 
        A netCDF object that contains spatial data such as velocity of shear 
        stess.These can be generated by running a Delft3D model.
    variables: array of strings
        Name of variables to interpolate, e.g. 'turkin1', 'ucx', 'ucy' and 'ucz'.
        The full list can be found using "data.variables.keys()" in the console.
    points: string, DataFrame  
        Point to interpoate data onto. 
          'cells'- interpolates all data into cell coordinate system (Default)
          'faces'- interpolates all dada into face coordinate system 
          DataFrame of x, y, and z coordinates - Interpolates data onto user 
          povided points 
  
    Returns
    -------
    transformed_data: DataFrame  
        Variables on specified grid points saved under the input varable names 
        and the x, y, and z cordinates of those points. 
    '''
    
    assert isinstance(points, (str, pd.DataFrame)),('points must be a string ' 
                    +'or DataFrame')
    if isinstance ( points, str):
       assert any([points == 'cells', points=='faces']), ('points must be'
                                                          +' cells or faces')
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be nerCDF4 object'

    data_raw = {}
    for var in variables:
        var_data_df = get_all_data_points(data, var,time_index=-1)           
        data_raw[var] = var_data_df 
    if type(points) == pd.DataFrame:  
        print('points provided')
    elif points=='faces':
        points = data_raw['ucx'][['x','y','z']]
    elif points=='cells':
        points = data_raw['turkin1'][['x','y','z']]
    
    transformed_data= points.copy(deep=True)
    
    for var in variables :    
        transformed_data[var] = interp.griddata(data_raw[var][['x','y','z']],
                                        data_raw[var][var], points[['x','y','z']])
        idx= np.where(np.isnan(transformed_data[var]))
        
        if len(idx[0]):
            for i in idx[0]: 
                transformed_data[var][i]= (interp
                                          .griddata(data_raw[var][['x','y','z']], 
                                           data_raw[var][var],
                                           [points['x'][i],points['y'][i],
                                            points['z'][i]], method='nearest'))
            
    return transformed_data


def get_all_data_points(data, variable, time_index= -1):  
    '''
    Get data points from all layers in netcdf object generated from Delft3D using 
    get_layer_data function. 

    Parameters
    ----------
    data: netcdf4 object 
       A netCDF object that contains spatial data such as velocity or shear stess.
       These can be generated by running a Delft3D model. 
       running a Delft3D model.   
    variable: string
        Delft3D outputs many vairables that can be called. The full list can be 
        found using "data.variables.keys()" in the consol. 
    time_index: int
        A positive interger to pull the time step from the dataset. 
        Defalt is late time step -1.  
        
    Returns
    -------
    all_data: DataFrame 
        Dataframe with columns x, y, z, variable, and time. 
    '''  
    
    assert isinstance(time_index, int), 'time_index  must be a int'
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be nerCDF4 object'
    assert variable in data.variables.keys(), 'varaiable not reconized'

    max_time_index = len(data.variables[variable][:])
    assert time_index <= max_time_index, (f'time_index must be less than the'
                                          +'max time index {max_time_index}')
    assert time_index >= -1, 'time_index must be greater than or equal to -1'


    cords_to_layers= {'FlowElem_xcc FlowElem_ycc':{'name':'laydim', 
                                    'coords':data.variables['LayCoord_cc'][:]},
                       'FlowLink_xu FlowLink_yu': {'name':'wdim', 
                                'coords':data.variables['LayCoord_w'][:]}}

    layer_dim =  str(data.variables[variable].coordinates)
    
    try:    
        cord_sys= cords_to_layers[layer_dim]['coords']

    except: 
        raise Exception('coordinates not recognized')
    else: 
        Layer_percentages= np.ma.getdata(cord_sys, False) 
        
    bottom_depth=np.ma.getdata(data.variables['waterdepth'][time_index, :], False)

    if layer_dim == 'FlowLink_xu FlowLink_yu': 

        #interpolate 
        coords = str(data.variables['waterdepth'].coordinates).split()
        x_laydim=np.ma.getdata(data.variables[coords[0]][:], False) 
        y_laydim=np.ma.getdata(data.variables[coords[1]][:], False)
        points_laydim = np.array([ [x, y] for x, y in zip(x_laydim, y_laydim)])
        
        coords_request = str(data.variables[variable].coordinates).split()
        x_wdim=np.ma.getdata(data.variables[coords_request[0]][:], False) 
        y_wdim=np.ma.getdata(data.variables[coords_request[1]][:], False)
        points_wdim=np.array([ [x, y] for x, y in zip(x_wdim, y_wdim)])
        
        bottom_depth_wdim = interp.griddata(points_laydim, bottom_depth,
                                            points_wdim)
        
        idx= np.where(np.isnan(bottom_depth_wdim))
        
        for i in idx: 
            bottom_depth_wdim[i]= interp.griddata(points_laydim, bottom_depth,
                                             points_wdim[i], method='nearest')
        
    x_all=[]
    y_all=[]
    z_all=[]
    v_all=[]
    time_all=[]

    
    N_layers = range(len(Layer_percentages))
    for layer in N_layers:
        layer_data= get_layer_data(data, variable, layer, time_index)

        x_all=np.append(x_all, layer_data.x)
        y_all=np.append(y_all, layer_data.y)
        z_all=np.append(z_all, layer_data.z)
        v_all=np.append(v_all, layer_data.v)

        time_all= np.append(time_all, layer_data.time)
    
    known_points = np.array([ [x, y, z, v, time] for x, y, z, v, time in zip(x_all, y_all, 
                                                                z_all, v_all, time_all)])
    
    all_data= pd.DataFrame(known_points, columns=['x','y','z',f'{variable}', 'time'])

    
    return all_data



def turbulent_intensity(data, points='cells', time_index= -1,
                        intermediate_values = False ):
    '''
    Calculated the turbulent intesity for a given data set for the specified
    points. Assumes variable names: turkin1, ucx, ucy and ucz.

    Parameters
    ----------
    data: netcdf4 object 
       A netCDF object that contains spatial data such as velocity or shear stess.
       These can be generated by running a Delft3D model.  
    points: string, DataFrame  
        Point to interpoate data onto. 
          'cells': interpolates all data into velocity coordinat system (Default)
          'faces': interpolates all dada into TKE coordinate system 
          DataFrame of x, y, and z corrdinates: Interpolates data onto user 
          povided points 
    time_index: float 
        A positive interger to pull the time step from the dataset. Defalt is
        late time step -1.  
    intermediate_values: boolean
        If true will return ucx, uxy, uxz,and turkine1 vaues in Dataframe 
        if false will only return x,y,z, and turbulent intesity values. False 
        is the default value      
        
    Returns
    -------
    TI_data: Dataframe
        If intermediate_values is true all values are output 
        If intermediate_values is equal to false only turbulent_intesity and 
        x, y, and z varibles are output 
            turbulet_intesity- turbulent kinetic energy divided by the root
                                mean squared velocity
            turkin1- turbulent kinetic energy 
            ucx- velocity in the x direction 
            ucy- velocity in the y direction 
            ucx- velocity in the z direction 
            x- position in the x direstion 
            y- position in the y direction 
            z- position in the z direction 
    '''
    
    assert isinstance(points, (str, pd.DataFrame)),('points must a string or'
                                                    +' DataFrame')
    if isinstance ( points, str):
       assert any([points == 'cells', points=='faces']), ('points must be cells'
                                                          +' or faces')
    assert isinstance(time_index, int), 'time_index  must be a int'
    assert type(data)== netCDF4._netCDF4.Dataset, 'data must be nerCDF4 object'
    assert 'turkin1' in data.variables.keys(), ('Varaiable Turkine 1 not'
                                                +' present in Data')
    assert 'ucx' in data.variables.keys(),'Varaiable ucx 1 not present in Data'
    assert 'ucy' in data.variables.keys(),'Varaiable ucy 1 not present in Data'
    assert 'ucz' in data.variables.keys(),'Varaiable ucz 1 not present in Data'

    TI_vars= ['turkin1', 'ucx', 'ucy', 'ucz']
    TI_data_raw = {}
    for var in TI_vars:
        #get all data
        var_data_df = get_all_data_points(data, var ,time_index)           
        TI_data_raw[var] = var_data_df 
    if type(points) == pd.DataFrame:  
        print('points provided')
    elif points=='faces':
        points = TI_data_raw['turkin1'].drop(['turkin1'],axis=1)
    elif points=='cells':
        points = TI_data_raw['ucx'].drop(['ucx'],axis=1)
       
    TI_data = points.copy(deep=True)

    for var in TI_vars:    
        TI_data[var] = interp.griddata(TI_data_raw[var][['x','y','z']],
                                TI_data_raw[var][var], points[['x','y','z']])
        idx= np.where(np.isnan(TI_data[var]))
        
        if len(idx[0]):
            for i in idx[0]: 
                TI_data[var][i]= interp.griddata(TI_data_raw[var][['x','y','z']], 
                                TI_data_raw[var][var],
                                [points['x'][i],points['y'][i], points['z'][i]],
                                method='nearest')

    u_mag=unorm(np.array(TI_data['ucx']),np.array(TI_data['ucy']), 
                np.array(TI_data['ucz']))
    
    neg_index=np.where( TI_data['turkin1']<0)
    zero_bool= np.isclose( TI_data['turkin1'][ TI_data['turkin1']<0].array, 
               np.zeros(len( TI_data['turkin1'][TI_data['turkin1']<0].array)),
               atol=1.0e-4)
    zero_ind= neg_index[0][zero_bool]
    non_zero_ind= neg_index[0][~zero_bool]
    TI_data.loc[zero_ind,'turkin1']=np.zeros(len(zero_ind))
    TI_data.loc[non_zero_ind,'turkin1']=[np.nan]*len(non_zero_ind)
        
    TI_data['turbulent_intensity']= np.sqrt(2/3*TI_data['turkin1'])/u_mag
    
    if intermediate_values == False:
        TI_data= TI_data.drop(TI_vars, axis = 1)
        
    return TI_data
